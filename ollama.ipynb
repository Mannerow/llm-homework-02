{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a seperate terminal, run the following command: \n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    -v ollama:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the Ollama docker container is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE           COMMAND               CREATED              STATUS              PORTS                                                      NAMES\n",
      "285552c69cf6   ollama/ollama   \"/bin/ollama serve\"   About a minute ago   Up About a minute   11434/tcp, 0.0.0.0:11435->11435/tcp, :::11435->11435/tcp   ollama\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the Ollama docker container and download the gemma:2b model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling c1864a5eb193... 100% ▕████████████████▏ 1.7 GB                         \n",
      "pulling 097a36493f71... 100% ▕████████████████▏ 8.4 KB                         \n",
      "pulling 109037bec39c... 100% ▕████████████████▏  136 B                         \n",
      "pulling 22a838ceb7fb... 100% ▕████████████████▏   84 B                         \n",
      "pulling 887433b89a90... 100% ▕████████████████▏  483 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!docker exec -it ollama ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the following prompt: \n",
    "\n",
    "\"10 * 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[?25l\u001b[2K\u001b[1G\u001b[?25h\u001b[2K\u001b[1G\u001b[?25hSure\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h here\u001b[?25l\u001b[?25h'\u001b[?25l\u001b[?25hs\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h answer\u001b[?25l\u001b[?25h:\u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25h1\u001b[?25l\u001b[?25h0\u001b[?25l\u001b[?25h *\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h1\u001b[?25l\u001b[?25h0\u001b[?25l\u001b[?25h<sup>\u001b[?25l\u001b[?25hend\u001b[?25l\u001b[?25h_\u001b[?25l\u001b[?25hof\u001b[?25l\u001b[?25h_\u001b[?25l\u001b[?25hturn\u001b[?25l\u001b[?25h</sup>\u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25hThis\u001b[?25l\u001b[?25h expression\u001b[?25l\u001b[?25h evaluates\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h1\u001b[?25l\u001b[?25h0\u001b[?25l\u001b[?25h0\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h which\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h result\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h1\u001b[?25l\u001b[?25h0\u001b[?25l\u001b[?25h multiplied\u001b[?25l\u001b[?25h by\u001b[?25l\u001b[?25h i\u001b[1D\u001b[K\n",
      "itself\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h1\u001b[?25l\u001b[?25h0\u001b[?25l\u001b[?25h times\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker exec -it ollama ollama run gemma:2b \"10 * 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't want to pull the weights every time we run the docker container. Instead of mapping the /root/.ollama folder to a named volume, let's map it to a local directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama\n"
     ]
    }
   ],
   "source": [
    "# stop the current container\n",
    "!docker stop ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# Verify that it is no longer running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local directory for the Ollama files\n",
    "!mkdir ollama_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a seperate terminal, run the following command: \n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    -v ./ollama_files:/root/.ollama \\\n",
    "    -p 11435:11435 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE           COMMAND               CREATED         STATUS         PORTS                                                      NAMES\n",
      "42b501f47645   ollama/ollama   \"/bin/ollama serve\"   6 seconds ago   Up 5 seconds   11434/tcp, 0.0.0.0:11435->11435/tcp, :::11435->11435/tcp   ollama\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it ollama ollama pull gemma:2b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6G\tollama_files/models/blobs\n",
      "8.0K\tollama_files/models/manifests/registry.ollama.ai/library/gemma\n",
      "12K\tollama_files/models/manifests/registry.ollama.ai/library\n",
      "16K\tollama_files/models/manifests/registry.ollama.ai\n",
      "20K\tollama_files/models/manifests\n",
      "1.6G\tollama_files/models\n"
     ]
    }
   ],
   "source": [
    "!du -h ollama_files/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama\n"
     ]
    }
   ],
   "source": [
    "!docker stop ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will add the model weights to a new image. To accomplish this, we will create a Dockerfile in the root directory:\n",
    "\n",
    "```bash\n",
    "FROM ollama/ollama\n",
    "\n",
    "COPY ./ollama_files /root/.ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the new image\n",
    "!docker build -t ollama-gemma2b ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will run the new docker image\n",
    "\n",
    "In a seperate terminal, run the command: \n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 11434:11434 ollama-gemma2b\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE            COMMAND               CREATED          STATUS          PORTS                                           NAMES\n",
      "b8ddd5d0e768   ollama-gemma2b   \"/bin/ollama serve\"   11 seconds ago   Up 10 seconds   0.0.0.0:11434->11434/tcp, :::11434->11434/tcp   amazing_jennings\n"
     ]
    }
   ],
   "source": [
    "# Verify that it's running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the formula for energy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gemma:2b',\n",
    "    temperature=0.0,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's the formula for energy:\n",
      "\n",
      "**E = K + U**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **E** is the energy in joules (J)\n",
      "* **K** is the kinetic energy in joules (J)\n",
      "* **U** is the potential energy in joules (J)\n",
      "\n",
      "**Kinetic energy (K)** is the energy an object possesses when it moves or is in motion. It is calculated as half the product of an object's mass (m) and its velocity (v) squared:\n",
      "\n",
      "**K = 1/2mv^2**\n",
      "\n",
      "**Potential energy (U)** is the energy an object possesses due to its position or configuration. It is calculated as the product of an object's mass, gravitational constant (g), and height or position above a reference point.\n",
      "\n",
      "**U = mgh**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **m** is the mass in kilograms (kg)\n",
      "* **g** is the gravitational constant (9.8 m/s^2)\n",
      "* **h** is the height or position in meters (m)\n",
      "\n",
      "The formula shows that energy can be expressed as the sum of kinetic and potential energy. The kinetic energy is a measure of the object's ability to do work, while the potential energy is a measure of the object's ability to do work against a force.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
